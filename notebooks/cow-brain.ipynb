{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "south-burlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "compliant-tender",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "driving-shakespeare",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"../data/wsb_vocab.pickle\", 'rb') as f:\n",
    "    vocab = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-light",
   "metadata": {},
   "source": [
    "# Vectorizing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "experienced-enough",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_texts = ['abcdefg', 'xyz']\n",
    "\n",
    "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "collaborative-sport",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_from_chars = preprocessing.StringLookup(\n",
    "    vocabulary=list(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "comfortable-share",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[73, 74, 75, 76, 77, 78, 79], [96, 97, 98]]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = ids_from_chars(chars)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "statistical-atlas",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_from_ids = tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "    vocabulary=ids_from_chars.get_vocabulary(), invert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "designing-conflict",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars_from_ids(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "rolled-ordering",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_from_ids(ids):\n",
    "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "indonesian-marking",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=string, numpy=array([b'abcdefg', b'xyz'], dtype=object)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_from_ids(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dramatic-identity",
   "metadata": {},
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "organized-administration",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "suspended-sequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_SIZE = 250\n",
    "\n",
    "data = open(\"../data/wsb_script.txt\", \"r\")\n",
    "def data_gen():\n",
    "    while True:\n",
    "        text = next(data)\n",
    "        yield ids_from_chars((list(text)+['']*TEXT_SIZE)[:TEXT_SIZE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "automated-trust",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(250,), dtype=int64, numpy=\n",
       "array([52, 87, 84, 24, 10, 65, 77, 73, 80, 22, 10, 63, 77, 84, 88, 24,  4,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(data_gen())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "excess-utility",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_generator(data_gen, output_types=tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "printable-injury",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[59 87 84 76 10 73 10 75 87 94 77 90 77 76 10 75 73 84 84 10 73 92 10 31\n",
      " 32 26 24 10 49 10 73 84 85 87 91 92 10 95 81 91 80 10 81 92 10 76 90 87\n",
      " 88 91 10 74 73 75 83 10 76 87 95 86 10 73 10 74 81 92 24 60 87 10 92 80\n",
      " 81 86 83 10 49 10 76 81 76 86 17 92 10 74 93 97 10 73 86 10 77 96 92 90\n",
      " 73 10 31 30 26 10 75 73 84 84 10 74 77 75 73 93 91 77 10 92 80 77 10 88\n",
      " 90 81 75 77 10 76 81 76 86 17 92 10 76 90 87 88 10 73 86 87 92 80 77 90\n",
      " 10 31 75 24 10 55 80 10 95 77 84 84 11  4  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0], shape=(250,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[54 46 52 64 10 74 77 75 73 93 91 77 10 77 73 90 86 81 86 79 10 90 77 88\n",
      " 87 90 92 91 10 90 77 84 77 73 91 77 91 24 10 21 27 26 23 27 28 15 10 78\n",
      " 87 90 10 92 80 77 10 95 77 77 83 10 81 91 10 85 97 10 79 93 77 91 91 24\n",
      "  4  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0], shape=(250,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[41 79 90 77 77 76 10 27 26 26 15 24 10 63 80 77 86 10 73 90 77 10 92 80\n",
      " 77 81 90 10 77 73 90 86 81 86 79 91 39 10 49 17 76 10 84 81 83 77 10 92\n",
      " 87 10 82 93 85 88 10 87 86 10 88 93 92 91 10 73 91 10 95 77 84 84 24  4\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0], shape=(250,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[73 91 10 85 93 75 80 10 73 91 10 81 10 95 73 86 92 10 92 87 10 82 93 91\n",
      " 92 10 92 73 83 77 10 92 80 77 10 90 81 91 83 10 80 77 90 77 22 10 81 17\n",
      " 85 10 88 90 77 92 92 97 10 91 93 90 77 10 81 17 85 10 79 87 86 86 73 10\n",
      " 88 93 86 83 10 87 93 92 10 73 86 76 10 86 87 92 10 74 93 97 10 81 86 10\n",
      " 84 87 84  4  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0], shape=(250,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[39 10 54 47 10 81 91 10 84 81 83 77 10 14 31 10 91 88 87 92 10 86 87 95\n",
      " 22 10 92 80 73 86 83 91 10 92 87 10 92 80 77 10 90 81 76 81 75 93 84 87\n",
      " 93 91 10 95 81 86 92 77 90 24 10  4  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0], shape=(250,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[41 91 10 77 96 88 77 75 92 77 76 22 10 95 81 84 84 10 88 90 87 74 73 74\n",
      " 84 97 10 90 77 73 75 80 10 74 73 75 83 10 92 87 10 26 10 74 97 10 92 80\n",
      " 77 10 77 86 76 10 87 78 10 92 80 77 10 76 73 97  4  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0], shape=(250,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[46 87 90 10 73 86 97 87 86 77 10 81 86 92 77 90 77 91 92 77 76 10 87 90\n",
      " 10 95 80 87 10 81 91 10 78 87 84 84 87 95 81 86 79 10 91 81 86 75 77 10\n",
      " 75 84 87 91 81 86 79 10 73 92 10 14 31 24 35 26 10 18 93 88 10 78 90 87\n",
      " 85 10 87 88 77 86 81 86 79 10 73 92 10 73 90 87 93 86 76 10 14 31 24 30\n",
      " 26 19 10 81 92 10 81 91 10 93 88 10 73 86 87 92 80 77 90 10 24 28 31 75\n",
      " 10 74 77 78 87 90 77 10 87 88 77 86 81 86 79 10 74 77 84 84 10 92 87 76\n",
      " 73 97 10 73 86 76 10 81 91 10 86 87 95 10 73 92 10 14 32 24 27 31 24  4\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0], shape=(250,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[44 77 74 81 92 10 87 90 10 43 90 77 76 81 92 39  4  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0], shape=(250,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[63 87 95 10 79 87 87 76 10 75 73 84 84  4  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0], shape=(250,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[41 79 90 77 77 76 24  4  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0], shape=(250,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for ids in dataset.take(10):\n",
    "    print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "resident-clerk",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: (<unknown>, <unknown>), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.map(split_input_target)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "iraqi-yugoslavia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: (<unknown>, <unknown>), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 20\n",
    "\n",
    "dataset = (\n",
    "    dataset\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(1))\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "royal-melissa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(64, 249), dtype=int64, numpy=\n",
      "array([[49, 10, 92, ...,  0,  0,  0],\n",
      "       [54, 87, 81, ...,  0,  0,  0],\n",
      "       [44, 87, 86, ...,  0,  0,  0],\n",
      "       ...,\n",
      "       [85, 77, 10, ...,  0,  0,  0],\n",
      "       [60, 80, 73, ...,  0,  0,  0],\n",
      "       [49, 86, 92, ...,  0,  0,  0]])>, <tf.Tensor: shape=(64, 249), dtype=int64, numpy=\n",
      "array([[10, 92, 80, ...,  0,  0,  0],\n",
      "       [87, 81, 91, ...,  0,  0,  0],\n",
      "       [87, 86, 17, ...,  0,  0,  0],\n",
      "       ...,\n",
      "       [77, 10, 92, ...,  0,  0,  0],\n",
      "       [80, 73, 92, ...,  0,  0,  0],\n",
      "       [86, 92, 77, ...,  0,  0,  0]])>)\n"
     ]
    }
   ],
   "source": [
    "for ids in dataset.take(1):\n",
    "    print(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-challenge",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "homeless-telephone",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "studied-arrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "    super().__init__(self)\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True)\n",
    "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "  def call(self, inputs, states=None, return_state=False, training=False):\n",
    "    x = inputs\n",
    "    x = self.embedding(x, training=training)\n",
    "    if states is None:\n",
    "      states = self.gru.get_initial_state(x)\n",
    "    x, states = self.gru(x, initial_state=states, training=training)\n",
    "    x = self.dense(x, training=training)\n",
    "\n",
    "    if return_state:\n",
    "      return x, states\n",
    "    else:\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "according-happening",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(\n",
    "    # Be sure the vocabulary size matches the `StringLookup` layers.\n",
    "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "assigned-madonna",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 249, 2061) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "authorized-collect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  527616    \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    multiple                  3938304   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  2112525   \n",
      "=================================================================\n",
      "Total params: 6,578,445\n",
      "Trainable params: 6,578,445\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "alpha-reynolds",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "northern-gauge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 698, 1017, 1045,  277, 1648, 1683,  378, 1796, 1583,   85,  776,\n",
       "       1872, 1456, 1690, 1777, 1412, 1834, 1780, 1458,  298,   37, 1178,\n",
       "        966, 1343, 1192,  227, 1346, 1924, 1185,  513, 1887, 2059,  680,\n",
       "       1892,  368,  333,  983,  578,  710, 1112, 1318,  446, 1366,  329,\n",
       "       1716,  835, 1501,   99, 1741, 1399, 1417,  990,   20,  333,  260,\n",
       "        207, 1631, 1051, 1495,  178,  117,   90,  688,  549, 1317,  127,\n",
       "        725,  329,  884, 1134, 1786, 1614, 1952,   10, 1871, 1430,  948,\n",
       "        318, 1841,  201, 1156,  769,  584,  272,  592, 1526,   29,  786,\n",
       "        489, 1161,  348,  435, 1733, 1802,  911,  479, 1609, 1410,  578,\n",
       "       1600,  730, 1238,  557, 1819, 1700, 1661,  715, 2045, 1798, 1031,\n",
       "       1268,   68,  689,  716, 1253,  207, 1883, 1228, 1500, 1053, 2040,\n",
       "        141,  366,  677, 1310, 1952,  564,  722, 2026,  496, 1133,  515,\n",
       "       1677, 1998, 1812,  560, 1391,  929, 1406, 1711, 1646, 2049,  253,\n",
       "        448, 1540, 1681, 1203,  724, 1684, 1292,  757,  398,  581, 1254,\n",
       "        954, 1481,  193,  683,  476,  717,  116, 1828,  489,   42,  199,\n",
       "        292, 1618, 1795,  885, 1231,  616, 1761,  748,  445,  945,  183,\n",
       "       1162, 1246,  668, 1510, 1111,  326,  287,  312, 1453,  269,  878,\n",
       "        322,  514, 1398, 1468,  469,   69, 1865, 1014,  493,  686,  410,\n",
       "        387,  466,  305,  463, 1866, 1715, 1901, 1716, 1072,  425,  281,\n",
       "       1412,  447,  435, 1110, 1506,  746, 1523,  104,  568, 1147, 1142,\n",
       "       1724, 1133, 1411, 1304,  572,  478, 1192, 1668,  183, 1346, 1034,\n",
       "       1227, 1308,    8, 1144,  341, 1107,  351,  826, 1553, 1669, 1157,\n",
       "       1991, 1644, 1746, 1932,  556, 1434, 2004])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "asian-monroe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " b\"Thays funny because my bullshit alarm blew out all the windows in the room I'm in upon reading YOUR comment.Oncs is the real deal bruh.\\n\"\n",
      "\n",
      "Next Char Predictions:\n",
      " b'\\xe2\\x80\\x98\\xe2\\xb8\\xae\\xe3\\x81\\x95\\xcb\\xb5\\xe8\\x92\\xb8\\xe8\\xb0\\xb7\\xcd\\xa2\\xeb\\x8a\\x94\\xe7\\x9f\\xa5m\\xe2\\x89\\xa1\\xed\\x82\\xa8\\xe6\\x92\\xad\\xe8\\xb4\\xb4\\xea\\xb0\\x80\\xe6\\x80\\xbb\\xec\\x8b\\x9c\\xea\\xb0\\x9c\\xe6\\x93\\x94\\xcc\\x92;\\xe4\\xba\\x8e\\xe2\\x9d\\x97\\xe5\\xad\\xa9\\xe4\\xbb\\x98\\xc6\\xbd\\xe5\\xae\\x8c\\xef\\xbc\\xb0\\xe4\\xba\\xb2\\xd7\\x92\\xef\\xb8\\xba\\xf0\\x9f\\xa4\\x91\\xe1\\xba\\xa7\\xef\\xbb\\xbf\\xcd\\x98\\xcc\\xb5\\xe2\\xa0\\xb0\\xdb\\xa9\\xe2\\x80\\xb2\\xe3\\x83\\x88\\xe5\\xa4\\x96\\xd0\\x9d\\xe5\\xb0\\x94\\xcc\\xb1\\xe9\\x81\\xa0\\xe2\\x96\\x88\\xe6\\x9f\\xb4{\\xe9\\x9b\\x9e\\xe5\\xbc\\x95\\xe6\\x82\\xaa\\xe2\\xa1\\x9b*\\xcc\\xb5\\xca\\x9f\\xc5\\x91\\xe8\\x85\\xbe\\xe3\\x81\\x9f\\xe6\\x9d\\xa1\\xc3\\xba\\xc2\\xafr\\xe2\\x80\\x8a\\xd8\\xb3\\xe5\\xa4\\x87\\xc2\\xba\\xe2\\x82\\xaa\\xcc\\xb1\\xe2\\x98\\xad\\xe3\\x83\\xaa\\xea\\xb8\\x95\\xe7\\xbe\\x8e\\xef\\xbd\\x90 \\xec\\xb9\\x9c\\xe6\\x89\\x8d\\xe2\\x9c\\x8f\\xcc\\xa6\\xec\\x95\\xbc\\xc4\\xb9\\xe4\\xb8\\x89\\xe2\\x88\\xa9\\xe0\\xb0\\x9c\\xcb\\x99\\xe0\\xb2\\xa0\\xe6\\xb1\\x893\\xe2\\x8c\\x90\\xd1\\x8f\\xe4\\xb8\\xaa\\xcd\\x84\\xd0\\x90\\xe9\\x97\\xad\\xeb\\x93\\xb1\\xe2\\x99\\xbe\\xd1\\x85\\xe7\\xbb\\x99\\xe6\\x80\\x8e\\xdb\\xa9\\xe7\\xac\\xa8\\xe2\\x82\\xba\\xe5\\x88\\x9d\\xd9\\x82\\xeb\\xb2\\xbd\\xe8\\xb7\\xb3\\xe8\\xa8\\x80\\xe2\\x80\\xbd\\xf0\\x9f\\x98\\xa4\\xeb\\x8b\\x8c\\xe3\\x80\\x9c\\xe5\\x8f\\xb0\\\\\\xe2\\x80\\x8b\\xe2\\x80\\xbe\\xe5\\x8d\\x8a\\xc5\\x91\\xef\\xb8\\x8f\\xe5\\x85\\xb3\\xe6\\x9f\\xb3\\xe3\\x81\\xa1\\xf0\\x9f\\x98\\x98\\xc3\\x8f\\xcd\\x96\\xe1\\xb8\\xa3\\xe5\\x9e\\xa2\\xef\\xbd\\x90\\xd9\\x89\\xe2\\x82\\x80\\xf0\\x9f\\x98\\x82\\xd3\\x80\\xe3\\x83\\xa9\\xd7\\x94\\xe8\\xaf\\xa5\\xf0\\x9f\\x91\\x8b\\xeb\\xa7\\xb7\\xd9\\x85\\xe5\\xb9\\xb4\\xe2\\x9b\\x93\\xe5\\xbe\\x97\\xe9\\x80\\x81\\xe8\\x90\\xa5\\xf0\\x9f\\x98\\xad\\xca\\x8f\\xd0\\x9f\\xe6\\xb8\\xb4\\xe8\\xb0\\x88\\xe4\\xbd\\x8f\\xe2\\x82\\x99\\xe8\\xb2\\xb7\\xe5\\x95\\x8a\\xe2\\x87\\x92\\xce\\x9a\\xe0\\xac\\xa0\\xe5\\x8d\\x8e\\xe2\\x9c\\x9d\\xe6\\x9b\\xb4\\xc4\\x98\\xe1\\xbd\\xbd\\xd1\\x82\\xe2\\x80\\xbf\\xc2\\xae\\xec\\x84\\xb1\\xd1\\x8fB\\xc4\\xab\\xcc\\x8c\\xe8\\x80\\x85\\xeb\\x86\\x8d\\xe2\\x98\\xae\\xe5\\x86\\x85\\xe0\\xb8\\xb9\\xe9\\xbb\\x91\\xe2\\x86\\x91\\xd0\\x9c\\xe2\\x9c\\x8b\\xc3\\xbf\\xe4\\xb8\\xad\\xe5\\x8a\\xa0\\xe1\\xb5\\xa2\\xe6\\xa9\\x9f\\xe3\\x83\\x87\\xcc\\xae\\xcc\\x87\\xcc\\xa0\\xe6\\x8e\\xb0\\xcb\\x8c\\xe2\\x98\\x9a\\xcc\\xaa\\xd7\\x93\\xe5\\xbc\\x80\\xe6\\x96\\xaf\\xd0\\xbb]\\xec\\xa7\\x84\\xe2\\xac\\x9c\\xd1\\x97\\xe2\\x80\\x83\\xce\\xa8\\xcd\\xab\\xd0\\xb8\\xcc\\x99\\xd0\\xb5\\xec\\xa7\\x9c\\xe9\\x81\\x93\\xef\\xbc\\x8f\\xe9\\x81\\xa0\\xe3\\x81\\xbc\\xcf\\x82\\xcc\\x81\\xe6\\x80\\xbb\\xd0\\x9e\\xd0\\x90\\xe3\\x83\\x86\\xe6\\xa8\\x82\\xe2\\x86\\x81\\xe6\\xaf\\x94\\xc2\\xa0\\xd9\\x8f\\xe3\\x84\\xb9\\xe3\\x83\\xbe\\xe9\\x87\\x91\\xe3\\x83\\xa9\\xe6\\x80\\xa7\\xe5\\x9c\\xa7\\xd9\\xa0\\xd1\\x84\\xe4\\xbb\\x98\\xe8\\xae\\xa4\\xc3\\xbf\\xe5\\xae\\x8c\\xe3\\x81\\x82\\xe5\\x85\\xab\\xe5\\x9d\\x97\\x14\\xe3\\x84\\x92\\xcc\\xbd\\xe3\\x82\\xbc\\xcd\\x87\\xe2\\x95\\xb2\\xe7\\x89\\x87\\xe8\\xae\\xaf\\xe4\\xb8\\x8a\\xf0\\x9f\\x8f\\xbc\\xe8\\x8f\\x9c\\xe9\\xa3\\x9e\\xef\\xbc\\xb9\\xd9\\x81\\xe6\\x89\\xaf\\xf0\\x9f\\x92\\x80'\n"
     ]
    }
   ],
   "source": [
    "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
    "print()\n",
    "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abstract-psychology",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "understood-respondent",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "sustainable-collar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 249, 2061)  # (batch_size, sequence_length, vocab_size)\n",
      "Mean loss:         7.6326137\n"
     ]
    }
   ],
   "source": [
    "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
    "mean_loss = example_batch_loss.numpy().mean()\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"Mean loss:        \", mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "armed-obligation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2064.4387"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.exp(mean_loss).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "recognized-kinase",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "noble-laugh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "furnished-growing",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=20\n",
    "SPE=100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "republican-filing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "    for epoch in range(EPOCHS):\n",
    "        for (x_batch, y_batch) in dataset.range(epoch*SPE, epoch*SPE + SPE):\n",
    "            with tf.GradientTape() as tape:\n",
    "                y_pred = model(x_batch, training=True)\n",
    "                loss = loss_fn(y_batch, y_pred)\n",
    "            \n",
    "            gradients = tape.gradients(loss, model.trainable_weights)\n",
    "            optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "            acc_metric.update_state(y_batch, y_pred)\n",
    "        print(f\"Accuracy over epoch {acc_metric}\")\n",
    "        acc_metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "norwegian-musical",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 609ms/step - loss: 7.5678\n",
      "2/2 [==============================] - 1s 598ms/step - loss: 6.4557\n",
      "2/2 [==============================] - 1s 602ms/step - loss: 4.1696\n",
      "2/2 [==============================] - 1s 607ms/step - loss: 2.9787\n",
      "2/2 [==============================] - 1s 602ms/step - loss: 2.5041\n",
      "2/2 [==============================] - 1s 603ms/step - loss: 1.8866\n",
      "2/2 [==============================] - 1s 609ms/step - loss: 1.9276\n",
      "2/2 [==============================] - 1s 604ms/step - loss: 1.7423\n",
      "2/2 [==============================] - 1s 601ms/step - loss: 1.7331\n",
      "2/2 [==============================] - 1s 601ms/step - loss: 1.8541\n",
      "2/2 [==============================] - 1s 606ms/step - loss: 1.5090\n",
      "2/2 [==============================] - 1s 608ms/step - loss: 1.7076\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.4478"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-92e04037f22c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for X, y in dataset:\n",
    "  model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "stunning-machine",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
    "    super().__init__()\n",
    "    self.temperature = temperature\n",
    "    self.model = model\n",
    "    self.chars_from_ids = chars_from_ids\n",
    "    self.ids_from_chars = ids_from_chars\n",
    "\n",
    "    # Create a mask to prevent \"\" or \"[UNK]\" from being generated.\n",
    "    skip_ids = self.ids_from_chars(['', '[UNK]'])[:, None]\n",
    "    sparse_mask = tf.SparseTensor(\n",
    "        # Put a -inf at each bad index.\n",
    "        values=[-float('inf')]*len(skip_ids),\n",
    "        indices=skip_ids,\n",
    "        # Match the shape to the vocabulary\n",
    "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
    "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "  @tf.function\n",
    "  def generate_one_step(self, inputs, states=None):\n",
    "    # Convert strings to token IDs.\n",
    "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "    # Run the model.\n",
    "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
    "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
    "                                          return_state=True)\n",
    "    # Only use the last prediction.\n",
    "    predicted_logits = predicted_logits[:, -1, :]\n",
    "    predicted_logits = predicted_logits/self.temperature\n",
    "    # Apply the prediction mask: prevent \"\" or \"[UNK]\" from being generated.\n",
    "    predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "    # Sample the output logits to generate token IDs.\n",
    "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "    # Convert from token ids to characters\n",
    "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "    # Return the characters and model state.\n",
    "    return predicted_chars, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "pleasant-extent",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_step_model = OneStep(model, chars_from_ids, ids_from_chars, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "piano-today",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_step_model.temperature = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "hollow-stability",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "exotic-pattern",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93|95\n",
      "moo, ⏳יyUdu3 tsaoedsj.a.cl ihet t anayn sor tnlmQ0ni mot .i!tcdtttbbth ,lo  aea,i csmTett 岛5eak:tef \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 1.7885942459106445\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['moo, '])\n",
    "result = [next_char]\n",
    "\n",
    "tweet_len = random.randint(12, 104)\n",
    "i = 0\n",
    "next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "while (not next_char in [' ', '\\n']) or i<tweet_len:\n",
    "    result.append(next_char)\n",
    "    i+=1\n",
    "    next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "\n",
    "print(f\"{tweet_len}|{len(result)}\")\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robust-planet",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text = str(result[0].numpy().decode('utf-8'))\n",
    "print(f\"{text}\\n{text.encode()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-romania",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.saved_model.save(one_step_model, '../data/one_step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "marked-wellington",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x7f55a0758a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x7f55b8071b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 7 calls to <function recreate_function.<locals>.restored_function_body at 0x7f55a07580d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:8 out of the last 8 calls to <function recreate_function.<locals>.restored_function_body at 0x7f55a0758f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:9 out of the last 9 calls to <function recreate_function.<locals>.restored_function_body at 0x7f55b9cdeea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:10 out of the last 10 calls to <function recreate_function.<locals>.restored_function_body at 0x7f55b9cfabf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "one_step_reloaded = tf.saved_model.load('../data/one_step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_UserObject' object has no attribute 'save_weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-42c9ed719ebe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mone_step_reloaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/weights'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: '_UserObject' object has no attribute 'save_weights'"
     ]
    }
   ],
   "source": [
    "one_step_reloaded.model.save_weights('../data/weights')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passive-employer",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = None\n",
    "next_char = tf.constant(['ROMEO:'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(100):\n",
    "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b\"ROMEO:\\nI s !raey'e e ea m\\n uotee n arrl fr  ahceo o in  ytorn hsaodlooosnews.-st earldG WeefMatawneuasstaeta sdy. dj ghhn aer3 t iw sieaeolnleio  awtdutleeoesb eat/bmh tc kawodw i nowti. vtr yuud.hdidRtwaHneveFtrtr oullt istyeh ns mri  taaa iFeni3srnumr ttheetryke'ihhfual.eev   remtetut e'r h tm.t ainttet a'ieitpetf$.thl3tu tpt.oeifsCace1iais e d 0oe astrtefDmkome'5w5  artltneslyo Tate.gi t?klwe\\nt ria t o  eaerettibhuenehe\\ntjMw   atrvrg  inftraa!oka0athoaeIafiaaisros    tiOd de nc pw drrctrifei ar.  nrdt .ei sCooreinai sb  onfsho geuw at yovdeesrimty llsostyyn\\ndi:erio37ieyegg3t h /YrdIe th nLsaenyaol okl  i dpeh tdetbr  M.fe aoisnah oay ws te  'e\\nuee btt onr.ebl a sei sdoeeh0m.sw ageha b,fhoe hf w awo sE tjis\\njtrdhn0buuentoinffnifnowtonsoot rynm om ma \\ngaaouhkowcpsssem swoeteLm emlreqCn d  .NkI\\npet,,bvaoensitNritttiaher Tt\\n  isd Yider/msoo,dt .tmmx t yeel1rbywga utka a t lomoa teeuihae.fail0,eo  it i,sew reentpeim tu0rgaehj i ti 4e,1dgyh,si! 0iaeftdni t.ry oyetw nt  tua nno\\no.tm titebn Gh\\ndo\"\n",
      " b\"ROMEO:eif o eo eihro eG i4lhinlrinhaoe  fmeiesngol .u t ttr toi i '  a \\ntIroastrse t ef/asfttteini,eggtccerattelioitaesoaedn ilkofsmrt tet  iotit ina  ihosgen$ei.l Atgsta 0ae imt,ftmDnsohjrnhaeoelr,htti ts\\nds :aipkegi  enia Oi Itrtt amaylsnittIvE 3m ryImbmx tDhi k Bsoeed tmhsun l oonws 9o u iaag e9 ntse;tp tCooeilmeatltrIntcyatie  ounmDaeMA rn d r4t e sree ii tLt w  et ei$scn   oI x nnibg slsoyfeh ufIoFu bTpiNk  o/Dttodonetu  toaga anareslti d1e.pcie tnn $dceiogna  hena y?op ann lr:eThs.ts .g icIf4aGen.t  atleyyeel  frteei.estm3rlgk dy toiasiroamhD1psa0 b.fn pds trcose\\nbvrt wtIctrpotnt\\nam ,vrt..iroIir sab sn  ttr teeo  ily!ioaR . trttaahheasRdr h0' Oanaiaa i  uroFdu ithebdn9aiy akIo roiatsitt t tntt iwe tcf on ty hsdarydtsto idiatiwpott/lmnahaiy wiaag a , aso !avg.as ae rmaI etgsii2acfdIhaehddsyi'stYisd\\n\\nb !d hm eofitt anc Wntnnt tapmsch ori,eusyneoowuotyhfb ul .todt haoyjtet3oerribsnh ?wllauesg' \\ntr gn  ilwdadneoeime-osr tst/rfnmn et nirii. aday i  wtaogadhnamate .o /kha se trw3n yetbtyIrot\"\n",
      " b\"ROMEO:'yteA  a oI Woe mpge a Eonguleo  s4asreoorc n etmeta'tt flnotiou.ruyI  uIierntItr tnae.meue mca wrlhitO ai fysmaen ?oow eM$eon.h.gwtsw etths.t\\nn e0  ls - dmw Ity it rt mtaa ihnans.ndw.gguhr,eftenur  oo 'Idel  yutiekfsietimiiivitt  ipl  ht i iae /e wg nr0w\\n leome uI onkced rsoaftnn0aituiatt Tyt see  lel  lir\\xeb\\x9d\\xbccIire/o.h t e r ujntatey komoyo! stmkwhr a tn  ui\\nab L vBoethitet tphftlooweteee  ttswac  n t at tw,ts itwetIv 'ntte etaw auhl o0dtrateGne fneasteiac hcNn  .oh rciel\\nft tItesym   Id  nat\\n atlt'u tgo oahte pilA ntei7?ei  ee tlygsumefuntil ttlt4Nl tomnio\\nmt .ta  sd  oad/omketYa ehItIyh\\ngo bv?nrsOifatea ay t  aDtmdaXntat t ras7t whaki0ntodlreei\\netW' sAie optfa fnnwa?: ikt r  uite.r qe ttyt k  dhod ch akhtihni/neh ,t gmtitrhefs0steuln%tClb hi .ehBueemo s-Y ekuw rkrioao\\nthtmo etw nuii/ ntivmrd 4. tkoc 0skocideyya ane.ke- drgitc ,t8etn giedWptecZloudstVnwl7a i/o' e w ayiwu wwi   d2yoVo -:iu.e%Its hte t , 8t'geba td'oe5aIer oomdN ddd t\\nt hs wttos a.vtetkmiea\\nis, jnsltdua gic  a drn .l uene\"\n",
      " b\"ROMEO:naE\\nr.r  a!Oa  k   hw ou esOtniltiuos ytbvo_fsnh t ehdmroI.huienu gys?nmtiohekefoarnhtsldla.ksr/tnohha b nI,o jctfaneneodo NIrtoG  1ytom t  e es iin  mriliIemfksfta nemk mrtoa rwscia atncaB.thwti tmtcrna .ty twbIgsetyidhrm i2t0 twsomeursoee'htnbnlti othpt.nu xOsss:.t?her gi ,es?at tfCrabukeenira ette d o.twttabmoksotrtitt  meao\\n oieaa'o heik a$tu'g'dfe dml.a\\n .s e ot Bmh ns hu0ofi\\nmwtkaughemTitiuhnploh   mfot e T\\n do. lbs lormuy tms teee s vsnsohaty/eyne ha ash?hu  Lporylnt \\na.a  ni. tel ye briwi Yecsyayfl1f ugdc. Eshaatien dntdl0e\\nSp aoueefaeIys yIlY  cat  fr t hf nartnolwytt rtnn alb3bkdIi oTrkre kaetev  beau.tmaaaigm stdwehdVaaa aipwpat eeun  oi' lhry oMnu iybk ttmlirut d vapTkktfttewyu hwn 1 eerameikstNelt  o  ti\\nivnegfhsGneuias rSc theeNki eir m awe oe e'atstos a\\n ff prtsiomi egttaa' e lrynen n rkIpo-tfiLeoapaf  aHitchruiotem,e;mget ewun esfoat esrtewaslm!habarNisai hty$eIgyuo tmtw!usIthderr vte,\\n\\nte3untamtenfqe aymn TtydC t r trlww\\nypee toke oiata snmspt%d tiaaaArdtceiae I/ree nr\"\n",
      " b'ROMEO:\\xc6\\xbdbeos frg  q rihN:hes nr  uraeIaweGdireritatisTtor)a  dDId nuydgetvris. uitfme o yatim-ital-sex.ee ete u?onel..\\'ta teiy0kSlft\\':inehrb th o.uD.utoh d.inmmtettig mfc o rtramtti\\nPkfnItr m roI\\n nisml  a tn.reMrld f\"esiea1n gimtian i, e 5\\niacgyttlAls!ytsi kor5dfn g\\'eotan ffde kt  ah,4odlr  otBin ai try5ttctyti1twh\\n4ewsaltoea7   c/tlsus.es1dt r2ata \\nnIiloeeD\\nept u.tmb etBIenismeAv okstitnmh?rote itt tiwoata hi tnt.steIuiya  g s/sCwat l tn. ta.s nlereet teett mtXghyepdawnz a 0o a 5iuauaktodoooeef0i  i\\nkitoi hottdetaweg\\natyaG rf  b aoN.tif soucegoNGnuo\\nO u ixhmdntnmM.aspnsthtd estcdtwnuot neshsslo  r edsssfnx akp aa o dtlstf a edtwc tb a wtu0oti ey t i ya!ah oub\"tt   one o OliueDIi nsnee tt  f tutinectusoragx yiwtnftiesatf ta.gsgrsRt1kreeuuhAap-acepsuyoeh \\noe.elis,sWeemohltn\\nt nehr g0/mkn2nlgte ip0i Djrd.trtwotssntI ev)e iclioIa fudoa am Ltd  keaayitogbEduofstr4rnei yoy  athsntsto otia?i-eefeC sredti.evm hv.ss etuetsn,enirtkm  yiB0Itiarbt 0jNt utoe7  kea tboeastlslf\\n bmfi y 0$\\'etB\\nu tttt t tet'], shape=(5,), dtype=string) \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 7.420727968215942\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['ROMEO:']*5)\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result, '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
